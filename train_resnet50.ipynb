{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b5bc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from typing import Tuple, List, Dict\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd2c536",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingConfig:\n",
    "    \"\"\"Configuration class for training parameters\"\"\"\n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.data_dir = \"ham10000_processed\"\n",
    "        self.batch_size = 32\n",
    "        self.num_epochs = 15\n",
    "        self.learning_rate = 1e-4\n",
    "        self.weight_decay = 1e-4\n",
    "        self.dropout_rate = 0.3\n",
    "        self.label_smoothing = 0.1\n",
    "        self.train_split = 0.8\n",
    "        self.num_workers = 4\n",
    "        self.scheduler_patience = 3\n",
    "        self.scheduler_factor = 0.5\n",
    "        \n",
    "    def print_config(self):\n",
    "        \"\"\"Print current configuration\"\"\"\n",
    "        print(\"Training Configuration:\")\n",
    "        print(f\"  Device: {self.device}\")\n",
    "        print(f\"  Data Directory: {self.data_dir}\")\n",
    "        print(f\"  Batch Size: {self.batch_size}\")\n",
    "        print(f\"  Epochs: {self.num_epochs}\")\n",
    "        print(f\"  Learning Rate: {self.learning_rate}\")\n",
    "        print(f\"  Weight Decay: {self.weight_decay}\")\n",
    "        print(f\"  Dropout Rate: {self.dropout_rate}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Initialize configuration\n",
    "config = TrainingConfig()\n",
    "config.print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0ed2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms():\n",
    "    \"\"\"Create train and validation transforms\"\"\"\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.2),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return train_transform, val_transform\n",
    "\n",
    "def create_data_loaders(data_dir: str, config: TrainingConfig):\n",
    "    \"\"\"Create train and validation data loaders\"\"\"\n",
    "    print(\"Loading dataset...\")\n",
    "    \n",
    "    # Get transforms\n",
    "    train_transform, val_transform = get_transforms()\n",
    "    \n",
    "    # Load full dataset to get classes\n",
    "    full_dataset = datasets.ImageFolder(root=data_dir)\n",
    "    num_classes = len(full_dataset.classes)\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    print(f\"Classes: {full_dataset.classes}\")\n",
    "    \n",
    "    # Train/val split\n",
    "    train_size = int(config.train_split * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    train_indices, val_indices = torch.utils.data.random_split(\n",
    "        range(len(full_dataset)), [train_size, val_size]\n",
    "    )\n",
    "    \n",
    "    # Create separate datasets with different transforms\n",
    "    train_dataset = torch.utils.data.Subset(\n",
    "        datasets.ImageFolder(root=data_dir, transform=train_transform), \n",
    "        train_indices.indices\n",
    "    )\n",
    "    val_dataset = torch.utils.data.Subset(\n",
    "        datasets.ImageFolder(root=data_dir, transform=val_transform), \n",
    "        val_indices.indices\n",
    "    )\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config.batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=config.num_workers, \n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=config.batch_size, \n",
    "        shuffle=False,\n",
    "        num_workers=config.num_workers, \n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Train samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    return train_loader, val_loader, num_classes\n",
    "\n",
    "# Test the functions\n",
    "train_loader, val_loader, num_classes = create_data_loaders(config.data_dir, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c89e6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_classes: int, config: TrainingConfig):\n",
    "    \"\"\"Create and setup ResNet50 model\"\"\"\n",
    "    print(\"Creating ResNet50 model...\")\n",
    "    \n",
    "    # Load pre-trained ResNet50\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "    \n",
    "    # Replace the final layer for our number of classes\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(config.dropout_rate),\n",
    "        nn.Linear(model.fc.in_features, num_classes)\n",
    "    )\n",
    "    \n",
    "    # Move to device\n",
    "    model = model.to(config.device)\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def setup_training_components(model, config: TrainingConfig):\n",
    "    \"\"\"Setup loss function, optimizer, and scheduler\"\"\"\n",
    "    print(\"Setting up training components...\")\n",
    "    \n",
    "    # Loss function with label smoothing\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=config.label_smoothing)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=config.learning_rate, \n",
    "        weight_decay=config.weight_decay\n",
    "    )\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \n",
    "        mode='max', \n",
    "        factor=config.scheduler_factor, \n",
    "        patience=config.scheduler_patience, \n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    return criterion, optimizer, scheduler\n",
    "\n",
    "# Create model and training components\n",
    "model = create_model(num_classes, config)\n",
    "criterion, optimizer, scheduler = setup_training_components(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef42ed2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, config: TrainingConfig, epoch: int):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = total = 0\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(config.device, non_blocking=True), labels.to(config.device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Print progress every 30 batches\n",
    "        if batch_idx % 30 == 0:\n",
    "            print(f'Epoch {epoch+1}/{config.num_epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
    "\n",
    "    train_acc = correct / total\n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    return train_loss, train_acc\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, config: TrainingConfig):\n",
    "    \"\"\"Validate for one epoch\"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(config.device, non_blocking=True), labels.to(config.device, non_blocking=True)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_acc = correct / total\n",
    "    val_loss /= len(val_loader)\n",
    "    \n",
    "    return val_loss, val_acc\n",
    "\n",
    "def save_model(model, val_acc: float, best_val_acc: float, epoch: int):\n",
    "    \"\"\"Save model if it's the best so far\"\"\"\n",
    "    if val_acc > best_val_acc:\n",
    "        torch.save(model.state_dict(), \"best_resnet50_skin_cancer.pth\")\n",
    "        print(f\"New best model saved with val_acc: {val_acc:.4f}\")\n",
    "        return val_acc\n",
    "    return best_val_acc\n",
    "\n",
    "# Test one epoch (optional - comment out if you want to skip)\n",
    "print(\"Testing training functions...\")\n",
    "# train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, config, 0)\n",
    "# val_loss, val_acc = validate_epoch(model, val_loader, criterion, config)\n",
    "# print(f\"Test - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "# print(f\"Test - Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4888d57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Training Loop\n",
    "print(f\"Starting ResNet50 training for {config.num_epochs} epochs...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Training history\n",
    "train_accs, val_accs, train_losses, val_losses = [], [], [], []\n",
    "best_val_acc = 0.0\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(config.num_epochs):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Training phase\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, config, epoch)\n",
    "    train_accs.append(train_acc)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Validation phase\n",
    "    val_loss, val_acc = validate_epoch(model, val_loader, criterion, config)\n",
    "    val_accs.append(val_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_acc)\n",
    "    \n",
    "    # Save best model\n",
    "    best_val_acc = save_model(model, val_acc, best_val_acc, epoch)\n",
    "\n",
    "    # Print epoch results\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    print(f\"Epoch [{epoch+1}/{config.num_epochs}] - Time: {epoch_time:.2f}s\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, LR: {current_lr:.6f}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Save final model\n",
    "torch.save(model.state_dict(), \"final_resnet50_skin_cancer.pth\")\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(f\"Training completed!\")\n",
    "print(f\"Total training time: {total_time/60:.2f} minutes\")\n",
    "print(f\"Best validation accuracy: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62454847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_results(train_accs, val_accs, train_losses, val_losses, best_val_acc, config):\n",
    "    \"\"\"Plot training and validation metrics\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    epochs = range(1, len(train_accs) + 1)\n",
    "    \n",
    "    # Accuracy plot\n",
    "    ax1.plot(epochs, train_accs, label='Train Accuracy', marker='o', linewidth=2)\n",
    "    ax1.plot(epochs, val_accs, label='Validation Accuracy', marker='s', linewidth=2)\n",
    "    ax1.axhline(y=best_val_acc, color='r', linestyle='--', alpha=0.7, \n",
    "                label=f'Best Val Acc: {best_val_acc:.4f}')\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Accuracy\")\n",
    "    ax1.set_title(\"ResNet50 - Training and Validation Accuracy\")\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylim(0, 1)\n",
    "    \n",
    "    # Loss plot\n",
    "    ax2.plot(epochs, train_losses, label='Train Loss', marker='o', linewidth=2)\n",
    "    ax2.plot(epochs, val_losses, label='Validation Loss', marker='s', linewidth=2)\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"Loss\")\n",
    "    ax2.set_title(\"ResNet50 - Training and Validation Loss\")\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"resnet50_training_plot.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def print_final_summary(best_val_acc, config, total_params):\n",
    "    \"\"\"Print final training summary\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TRAINING SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Model: ResNet50\")\n",
    "    print(f\"Best Validation Accuracy: {best_val_acc:.4f} ({best_val_acc*100:.2f}%)\")\n",
    "    print(f\"Total Parameters: {total_params:,}\")\n",
    "    print(f\"Epochs Completed: {config.num_epochs}\")\n",
    "    print(f\"Final Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    print(f\"Dataset: {config.data_dir}\")\n",
    "    print(f\"Device: {config.device}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Plot results and show summary\n",
    "plot_training_results(train_accs, val_accs, train_losses, val_losses, best_val_acc, config)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print_final_summary(best_val_acc, config, total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d58dd1",
   "metadata": {},
   "source": [
    "# Model Evaluation and Testing\n",
    "\n",
    "Now you can load the best model and evaluate it on test data or use it for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7bc914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_model(model_path: str, num_classes: int, config: TrainingConfig):\n",
    "    \"\"\"Load the best saved model for inference\"\"\"\n",
    "    model = create_model(num_classes, config)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=config.device))\n",
    "    model.eval()\n",
    "    print(f\"Best model loaded from {model_path}\")\n",
    "    return model\n",
    "\n",
    "def predict_sample(model, val_loader, config, num_samples=5):\n",
    "    \"\"\"Predict on a few validation samples\"\"\"\n",
    "    class_names = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(val_loader):\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "                \n",
    "            images = images.to(config.device)\n",
    "            outputs = model(images)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            # Show results for first image in batch\n",
    "            true_label = labels[0].item()\n",
    "            pred_label = predicted[0].item()\n",
    "            confidence = probabilities[0][pred_label].item()\n",
    "            \n",
    "            print(f\"Sample {i+1}:\")\n",
    "            print(f\"  True: {class_names[true_label]}\")\n",
    "            print(f\"  Predicted: {class_names[pred_label]} (confidence: {confidence:.3f})\")\n",
    "            print(f\"  Correct: {'✓' if true_label == pred_label else '✗'}\")\n",
    "            print()\n",
    "\n",
    "# Example: Load best model and make predictions\n",
    "try:\n",
    "    best_model = load_best_model(\"best_resnet50_skin_cancer.pth\", num_classes, config)\n",
    "    predict_sample(best_model, val_loader, config, num_samples=3)\n",
    "except FileNotFoundError:\n",
    "    print(\"Best model not found. Run the training cells first!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
