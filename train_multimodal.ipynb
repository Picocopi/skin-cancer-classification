{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fe954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multimodal Skin Cancer Classification (Image + Metadata)\n",
    "\n",
    "This notebook builds and trains a multimodal deep learning model that uses both **skin lesion images** and **patient metadata** (age, sex, lesion location) to classify skin cancer. This approach is based on recent research showing that combining data sources can significantly improve accuracy compared to using images alone.\n",
    "\n",
    "**The process is as follows:**\n",
    "1.  **Load and Preprocess Data**: Load images and the `HAM10000_metadata.csv` file. Clean and transform the metadata into a numerical format.\n",
    "2.  **Create a Custom Dataset**: Build a PyTorch `Dataset` that provides an image, its corresponding metadata, and the label for each sample.\n",
    "3.  **Define the Multimodal Model**: Construct a model with two branches:\n",
    "    *   An **Image Branch** (a pre-trained CNN like EfficientNet) to learn from pixels.\n",
    "    *   A **Metadata Branch** (a simple MLP) to learn from tabular data.\n",
    "    *   A **Fusion Layer** that combines the outputs of both branches before making a final classification.\n",
    "4.  **Train the Model**: Implement a training loop to train the model on the combined dataset.\n",
    "5.  **Evaluate Performance**: Assess the model's accuracy on a held-out test set.\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import timm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"markdown\">\n",
    "## 1. Configuration\n",
    "Set up the main parameters for the training process.\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "# --- Configuration ---\n",
    "# Device (GPU/CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device.type == 'cpu':\n",
    "    print(\"Warning: Running on CPU. Training will be very slow. It is highly recommended to use a GPU.\")\n",
    "\n",
    "# Paths\n",
    "IMG_DIR = \"HAM10000_images\" \n",
    "METADATA_PATH = \"HAM10000/HAM10000_metadata.csv\"\n",
    "MODEL_CHOICE = \"efficientnet_b3\"\n",
    "\n",
    "# Training parameters\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 30\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "# --- End Configuration ---\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"markdown\">\n",
    "## 2. Load and Preprocess Metadata\n",
    "Load the CSV file containing patient metadata. We will perform several key preprocessing steps:\n",
    "- **Handle Missing Values**: The `age` column has missing values. We'll fill these with the mean age.\n",
    "- **Encode Categorical Features**: Convert `sex` and `localization` into numerical format using one-hot encoding.\n",
    "- **Scale Numerical Features**: Standardize the `age` column so it has a mean of 0 and a standard deviation of 1.\n",
    "- **Map Labels**: Create a mapping from the lesion type string (e.g., 'mel') to an integer index.\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell language=\"python\">\n",
    "# Load metadata\n",
    "df = pd.read_csv(METADATA_PATH)\n",
    "\n",
    "# --- Preprocessing Steps ---\n",
    "\n",
    "# 1. Handle missing age values\n",
    "df['age'].fillna(df['age'].mean(), inplace=True)\n",
    "\n",
    "# 2. Encode categorical features\n",
    "# One-hot encode 'sex' and 'localization'\n",
    "categorical_features = ['sex', 'localization']\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "encoded_categoricals = one_hot_encoder.fit_transform(df[categorical_features])\n",
    "\n",
    "# 3. Scale numerical features\n",
    "numerical_features = ['age']\n",
    "scaler = StandardScaler()\n",
    "scaled_numericals = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# 4. Combine processed features\n",
    "processed_metadata = np.hstack((scaled_numericals, encoded_categoricals))\n",
    "metadata_feature_count = processed_metadata.shape[1]\n",
    "\n",
    "print(f\"Metadata successfully processed.\")\n",
    "print(f\"Number of metadata features after encoding: {metadata_feature_count}\")\n",
    "\n",
    "# 5. Create label mapping\n",
    "lesion_type_dict = {\n",
    "    'akiec': 'Actinic Keratoses',\n",
    "    'bcc': 'Basal Cell Carcinoma',\n",
    "    'bkl': 'Benign Keratosis',\n",
    "    'df': 'Dermatofibroma',\n",
    "    'mel': 'Melanoma',\n",
    "    'nv': 'Melanocytic Nevi',\n",
    "    'vasc': 'Vascular Skin Lesions'\n",
    "}\n",
    "df['lesion_type'] = df['dx'].map(lesion_type_dict)\n",
    "df['label'] = pd.Categorical(df['dx']).codes\n",
    "\n",
    "# Store the mapping for later\n",
    "class_to_idx = {cls: i for i, cls in enumerate(pd.Categorical(df['dx']).categories)}\n",
    "idx_to_class = {i: cls for cls, i in class_to_idx.items()}\n",
    "num_classes = len(class_to_idx)\n",
    "\n",
    "print(f\"\\nClass to index mapping:\\n{class_to_idx}\")\n",
    "\n",
    "# Add processed metadata and image paths to the dataframe\n",
    "df['image_path'] = df['image_id'].apply(lambda x: os.path.join(IMG_DIR, x + '.jpg'))\n",
    "# This is a bit of a trick to store the numpy array in the dataframe\n",
    "df['processed_metadata'] = [processed_metadata[i] for i in range(len(processed_metadata))]\n",
    "\n",
    "df.head()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
